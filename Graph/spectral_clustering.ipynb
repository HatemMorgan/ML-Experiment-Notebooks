{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2ySDnkvGDFs"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvXE0pD4GDFx"
   },
   "source": [
    "# Project 4: Spectral clustering users based on their preferences (50 pt)\n",
    "\n",
    "The goal of this task is to find groups of users with similar preferences using **Spectral clustering**. \n",
    "You are given a fragment of the Yelp social network, represented by an undirected weighted graph.\n",
    "Nodes in the graph represent users.\n",
    "If two users are connected by an edge of weight $w$, it means that they have both left positive reviews to the same $w$ restaurants.\n",
    "\n",
    "Additionally, you are given a matrix `F` that encodes user preferences to different categories of restaurants. If `F[i, c] = 1`, then user `i` likes restaurants in category `c`.\n",
    "\n",
    "You are allowed to use the imported functions (`eigsh`, `KMeans`, `normalize`).\n",
    "\n",
    "## General remarks\n",
    "Do not add or modify any code outside of the following comment blocks, or where otherwise explicitly stated.\n",
    "\n",
    "``` python\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    "...\n",
    "##########################################################\n",
    "```\n",
    "After you fill in all the missing code, restart the kernel and re-run all the cells in the notebook.\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "\n",
    "If you plagiarise even for a single project task, you won't be eligible for the bonus this semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdQs6BcIGDFy"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "* `N` = number of users (nodes in the graph)\n",
    "* `C` = number of categories\n",
    "* The graph is stored as a _sparse adjacency matrix_ `A` (shape `[N, N]`).\n",
    "* User preferences are stored in a _feature matrix_ `F` (shape `[N, C]`). They will only be used for the final part of the assignment (Part 3)\n",
    "* Name of each category is provided in the list `categories` (length `[C]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFGiPKW3GDFz"
   },
   "outputs": [],
   "source": [
    "A = sp.load_npz('A.npz')\n",
    "F = np.load('F.npy')\n",
    "categories = np.load('categories.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En2tKgwLGDF3"
   },
   "outputs": [],
   "source": [
    "assert A.shape[0] == F.shape[0]\n",
    "assert F.shape[1] == len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "061t5pc0GDF7",
    "outputId": "7466a4fb-abdf-4366-a5c5-ea2d514ce72e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adjacency matrix is symmetric\n"
     ]
    }
   ],
   "source": [
    "print(f'The adjacency matrix is {\"symmetric\" if (A != A.T).sum() == 0 else \"asymmetric\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlZFTHbOGDF_"
   },
   "source": [
    "# 1. Implementing spectral clustering (35 pt)\n",
    "## 1.1. Construct the graph Laplacian (10 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eveU8VT-GDF_"
   },
   "source": [
    "First, we need to construct the Laplacian for the given graph (*Do only use sparse operations, see [Scipy Sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html)*). \n",
    "\n",
    "Given the **adjacency matrix** $A \\in \\mathbb{R}^{N \\times N},$ we define the **degree matrix** $D \\in \\mathbb{R}^{N \\times N}$ of an undirected graph as\n",
    "$$D_{ij} =  \\begin{cases}\\sum_{k=1}^N A_{ik} & if \\;\\; i = j\\\\ 0 & if \\;\\; i \\ne j\\end{cases}$$\n",
    "\n",
    "If our goal is to minimize the **ratio cut**, we will need to use the **unnormalized Laplacian**, defined as\n",
    "$$L_{unnorm} = D - A.$$\n",
    "\n",
    "If our goal is to minimze the **normalized cut**, we will need to use the **normalized Laplacian** (a.k.a. symmetrized Laplacian), defined as\n",
    "$$L_{sym} = I - D^{-1/2}AD^{-1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2ExAZhnGDGA"
   },
   "outputs": [],
   "source": [
    "def construct_laplacian(A: sp.csr_matrix, norm_laplacian: bool) -> sp.csr_matrix:\n",
    "    \"\"\"Construct Laplacian of a graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    norm_laplacian : bool\n",
    "        Whether to construct the normalized graph Laplacian or not.\n",
    "        If True, construct the normalized (symmetrized) Laplacian, L = I - D^{-1/2} A D^{-1/2}.\n",
    "        If False, construct the unnormalized Laplacian, L = D - A.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    L : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Laplacian of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    D = A.sum(axis=1).getA1() # getA1() flattened matrix into array\n",
    "    if not norm_laplacian:\n",
    "      L = sp.diags(D) - A\n",
    "    else:\n",
    "      D[D == 0] = 1 # to avoid division by zero\n",
    "      sqrt_inv_D = 1.0/np.sqrt(D) # D^{-1/2}\n",
    "      mat_D = sp.diags(sqrt_inv_D)\n",
    "      L = sp.eye(A.shape[0]) - mat_D.dot(A.dot(mat_D))\n",
    "    ##########################################################\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LorE0_BhGDGG"
   },
   "source": [
    "## 1.2. Spectral embedding (10 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdejkquxGDGH"
   },
   "source": [
    "Now, we have to compute the spectral embedding for the given graph.\n",
    "\n",
    "In order to partition the graph into $k$ clusters, such that the desired cut (ratio or normalized) is minimized, we need to consider the $k$ eigenvectors corresponding to the $k$ smallest eigenvalues of the graph Laplacian.\n",
    "\n",
    "Since the Laplacian matrix is sparse and symmetric, we can use the function `eigsh` from the `scipy.sparse.linalg` package in order to find eigendecomposition of $L$ (`eig` - eigendecomposition, `s` - sparse, `h`- Hermitian).\n",
    "The function `eigsh` directly allows you to find the smallest / largest eigenvalues by specifying the `k` and `which` parameters. \n",
    "\n",
    "Keep in mind that the Laplacian matrix is always positive semi-definite when picking the appropriate value for the `which` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CK6G4XoHGDGI"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_IhxbyOaGDGN",
    "outputId": "c8d20f72-9eaf-441c-d4a0-63fef077b523",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function eigsh in module scipy.sparse.linalg.eigen.arpack.arpack:\n",
      "\n",
      "eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
      "    Find k eigenvalues and eigenvectors of the real symmetric square matrix\n",
      "    or complex hermitian matrix A.\n",
      "    \n",
      "    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for\n",
      "    w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "    \n",
      "    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the\n",
      "    generalized eigenvalue problem for w[i] eigenvalues\n",
      "    with corresponding eigenvectors x[i].\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    A : ndarray, sparse matrix or LinearOperator\n",
      "        A square operator representing the operation ``A * x``, where ``A`` is\n",
      "        real symmetric or complex hermitian. For buckling mode (see below)\n",
      "        ``A`` must additionally be positive-definite.\n",
      "    k : int, optional\n",
      "        The number of eigenvalues and eigenvectors desired.\n",
      "        `k` must be smaller than N. It is not possible to compute all\n",
      "        eigenvectors of a matrix.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    w : array\n",
      "        Array of k eigenvalues.\n",
      "    v : array\n",
      "        An array representing the `k` eigenvectors.  The column ``v[:, i]`` is\n",
      "        the eigenvector corresponding to the eigenvalue ``w[i]``.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    M : An N x N matrix, array, sparse matrix, or linear operator representing\n",
      "        the operation ``M @ x`` for the generalized eigenvalue problem\n",
      "    \n",
      "            A @ x = w * M @ x.\n",
      "    \n",
      "        M must represent a real, symmetric matrix if A is real, and must\n",
      "        represent a complex, hermitian matrix if A is complex. For best\n",
      "        results, the data type of M should be the same as that of A.\n",
      "        Additionally:\n",
      "    \n",
      "            If sigma is None, M is symmetric positive definite.\n",
      "    \n",
      "            If sigma is specified, M is symmetric positive semi-definite.\n",
      "    \n",
      "            In buckling mode, M is symmetric indefinite.\n",
      "    \n",
      "        If sigma is None, eigsh requires an operator to compute the solution\n",
      "        of the linear equation ``M @ x = b``. This is done internally via a\n",
      "        (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "        iterative solver for a general linear operator.  Alternatively,\n",
      "        the user can supply the matrix or operator Minv, which gives\n",
      "        ``x = Minv @ b = M^-1 @ b``.\n",
      "    sigma : real\n",
      "        Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "        an operator to compute the solution of the linear system\n",
      "        ``[A - sigma * M] x = b``, where M is the identity matrix if\n",
      "        unspecified.  This is computed internally via a (sparse) LU\n",
      "        decomposition for explicit matrices A & M, or via an iterative\n",
      "        solver if either A or M is a general linear operator.\n",
      "        Alternatively, the user can supply the matrix or operator OPinv,\n",
      "        which gives ``x = OPinv @ b = [A - sigma * M]^-1 @ b``.\n",
      "        Note that when sigma is specified, the keyword 'which' refers to\n",
      "        the shifted eigenvalues ``w'[i]`` where:\n",
      "    \n",
      "            if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.\n",
      "    \n",
      "            if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.\n",
      "    \n",
      "            if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.\n",
      "    \n",
      "        (see further discussion in 'mode' below)\n",
      "    v0 : ndarray, optional\n",
      "        Starting vector for iteration.\n",
      "        Default: random\n",
      "    ncv : int, optional\n",
      "        The number of Lanczos vectors generated ncv must be greater than k and\n",
      "        smaller than n; it is recommended that ``ncv > 2*k``.\n",
      "        Default: ``min(n, max(2*k + 1, 20))``\n",
      "    which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']\n",
      "        If A is a complex hermitian matrix, 'BE' is invalid.\n",
      "        Which `k` eigenvectors and eigenvalues to find:\n",
      "    \n",
      "            'LM' : Largest (in magnitude) eigenvalues.\n",
      "    \n",
      "            'SM' : Smallest (in magnitude) eigenvalues.\n",
      "    \n",
      "            'LA' : Largest (algebraic) eigenvalues.\n",
      "    \n",
      "            'SA' : Smallest (algebraic) eigenvalues.\n",
      "    \n",
      "            'BE' : Half (k/2) from each end of the spectrum.\n",
      "    \n",
      "        When k is odd, return one more (k/2+1) from the high end.\n",
      "        When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``\n",
      "        (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "        at finding large values than small values.  If small eigenvalues are\n",
      "        desired, consider using shift-invert mode for better performance.\n",
      "    maxiter : int, optional\n",
      "        Maximum number of Arnoldi update iterations allowed.\n",
      "        Default: ``n*10``\n",
      "    tol : float\n",
      "        Relative accuracy for eigenvalues (stopping criterion).\n",
      "        The default value of 0 implies machine precision.\n",
      "    Minv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "        See notes in M, above.\n",
      "    OPinv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "        See notes in sigma, above.\n",
      "    return_eigenvectors : bool\n",
      "        Return eigenvectors (True) in addition to eigenvalues.\n",
      "        This value determines the order in which eigenvalues are sorted.\n",
      "        The sort order is also dependent on the `which` variable.\n",
      "    \n",
      "            For which = 'LM' or 'SA':\n",
      "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                algebraic value.\n",
      "    \n",
      "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                absolute value.\n",
      "    \n",
      "            For which = 'BE' or 'LA':\n",
      "                eigenvalues are always sorted by algebraic value.\n",
      "    \n",
      "            For which = 'SM':\n",
      "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                algebraic value.\n",
      "    \n",
      "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                decreasing absolute value.\n",
      "    \n",
      "    mode : string ['normal' | 'buckling' | 'cayley']\n",
      "        Specify strategy to use for shift-invert mode.  This argument applies\n",
      "        only for real-valued A and sigma != None.  For shift-invert mode,\n",
      "        ARPACK internally solves the eigenvalue problem\n",
      "        ``OP * x'[i] = w'[i] * B * x'[i]``\n",
      "        and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]\n",
      "        into the desired eigenvectors and eigenvalues of the problem\n",
      "        ``A * x[i] = w[i] * M * x[i]``.\n",
      "        The modes are as follows:\n",
      "    \n",
      "            'normal' :\n",
      "                OP = [A - sigma * M]^-1 @ M,\n",
      "                B = M,\n",
      "                w'[i] = 1 / (w[i] - sigma)\n",
      "    \n",
      "            'buckling' :\n",
      "                OP = [A - sigma * M]^-1 @ A,\n",
      "                B = A,\n",
      "                w'[i] = w[i] / (w[i] - sigma)\n",
      "    \n",
      "            'cayley' :\n",
      "                OP = [A - sigma * M]^-1 @ [A + sigma * M],\n",
      "                B = M,\n",
      "                w'[i] = (w[i] + sigma) / (w[i] - sigma)\n",
      "    \n",
      "        The choice of mode will affect which eigenvalues are selected by\n",
      "        the keyword 'which', and can also impact the stability of\n",
      "        convergence (see [2] for a discussion).\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ArpackNoConvergence\n",
      "        When the requested convergence is not obtained.\n",
      "    \n",
      "        The currently converged eigenvalues and eigenvectors can be found\n",
      "        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "        object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A\n",
      "    svds : singular value decomposition for a matrix A\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD\n",
      "    functions which use the Implicitly Restarted Lanczos Method to\n",
      "    find the eigenvalues and eigenvectors [2]_.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.sparse.linalg import eigsh\n",
      "    >>> identity = np.eye(13)\n",
      "    >>> eigenvalues, eigenvectors = eigsh(identity, k=6)\n",
      "    >>> eigenvalues\n",
      "    array([1., 1., 1., 1., 1., 1.])\n",
      "    >>> eigenvectors.shape\n",
      "    (13, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(eigsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2kZSC2KGDGR"
   },
   "outputs": [],
   "source": [
    "def spectral_embedding(A: sp.csr_matrix, num_clusters: int, norm_laplacian: bool) -> np.array:\n",
    "    \"\"\"Compute spectral embedding of nodes in the given graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    num_clusters : int\n",
    "        Number of clusters to detect in the data.\n",
    "    norm_laplacian : bool, default False\n",
    "        Whether to use the normalized graph Laplacian or not.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    embedding : np.array, shape [N, num_clusters]\n",
    "        Spectral embedding for the given graph.\n",
    "        Each row represents the spectral embedding of a given node.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (A != A.T).sum() != 0:\n",
    "        raise ValueError(\"Spectral embedding doesn't work if the adjacency matrix is not symmetric.\")\n",
    "    if num_clusters < 2:\n",
    "        raise ValueError(\"The clustering requires at least two clusters.\")\n",
    "    if num_clusters > A.shape[0]:\n",
    "        raise ValueError(f\"We can have at most {A.shape[0]} clusters (number of nodes).\")\n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    L = construct_laplacian(A, norm_laplacian)\n",
    "    _, eigenvectors = eigsh(L, k=num_clusters, which='SA')\n",
    "    ##########################################################\n",
    "    return eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4ZsLZwJGDGX"
   },
   "source": [
    "## 1.3. Determine the clusters based on the spectral embedding (15 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAGQ3-2SGDGY"
   },
   "source": [
    "You should use the K-means algorithm for assigning nodes to clusters, once the spectral embedding is computed.\n",
    "\n",
    "One thing you should keep in mind, is that when using the **normalized Laplacian**, the rows of the embedding matrix **have to** be normalized to have unit $L_2$ norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzCr9d2yGDGZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtLowcIXGDGd"
   },
   "outputs": [],
   "source": [
    "def spectral_clustering(A: sp.csr_matrix, num_clusters: int, norm_laplacian: bool, seed: int = 42) -> np.array:\n",
    "    \"\"\"Perform spectral clustering on the given graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    num_clusters : int\n",
    "        Number of clusters to detect in the data.\n",
    "    norm_laplacian : bool, default False\n",
    "        Whether to use the normalized graph Laplacian or not.\n",
    "    seed : int, default 42\n",
    "        Random seed to use for the `KMeans` clustering.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    z_pred : np.array, shape [N]\n",
    "        Predicted cluster indicators for each node.\n",
    "        \n",
    "    \"\"\"\n",
    "    model = KMeans(num_clusters, random_state=seed)\n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    embeddings = spectral_embedding(A, num_clusters, norm_laplacian)\n",
    "    if norm_laplacian:\n",
    "      embeddings = normalize(embeddings, norm='l2', axis=1)\n",
    "    \n",
    "    z_pred = model.fit_predict(embeddings)\n",
    "    ##########################################################\n",
    "    return z_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2Io7ycHGDGl"
   },
   "source": [
    "# 2. Quantitatively evaluate the results (10 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNq6ZONbGDGm"
   },
   "outputs": [],
   "source": [
    "def labels_to_list_of_clusters(z: np.array) -> List[List[int]]:\n",
    "    \"\"\"Convert predicted label vector to a list of clusters in the graph.\n",
    "    This function is already implemented, nothing to do here.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : np.array, shape [N]\n",
    "        Predicted labels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_clusters : list of lists\n",
    "        Each list contains ids of nodes that belong to the same cluster.\n",
    "        Each node may appear in one and only one partition.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = np.array([0, 0, 1, 1, 0])\n",
    "    >>> labels_to_list_of_clusters(z)\n",
    "    [[0, 1, 4], [2, 3]]\n",
    "    \n",
    "    \"\"\"\n",
    "    return [np.where(z == c)[0] for c in np.unique(z)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_079iCeGDGq"
   },
   "source": [
    "## 2.1. Compute ratio cut (5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EN-X05NRGDGq"
   },
   "source": [
    "Your task is to implement functions for computing the **ratio cut** and **normalized cut** for a given partition.\n",
    "\n",
    "Ratio cut and normalized cut are defined on the slide 14 of the lecture slides.\n",
    "\n",
    "\n",
    "The function `labels_to_list_of_clusters` can be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "z7p1XLRsUYkS",
    "outputId": "9829b71c-3a16-49cf-e3c4-9b45edf5f1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0   1.0   0.0   1.0   0.0   0.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t3.0\n",
      "  (1, 0)\t1.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(A[1,22], ' ', A[2,22], ' ', A[5, 22], ' ', A[1,3], ' ', A[2,3], ' ', A[5, 3])\n",
    "print(A[[1,2,5]][:, [22,3]])\n",
    "print(A[[1,2,5]][:, [22,3]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDUywmwQGDGr"
   },
   "outputs": [],
   "source": [
    "def compute_ratio_cut(A: sp.csr_matrix, z: np.array) -> float:\n",
    "    \"\"\"Compute the ratio cut for the given partition of the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        AdjA[1,10]acency matrix of the graph.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster indicators for each node.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ratio_cut : float\n",
    "        Value of the cut for the given partition of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    nodes_clusters = labels_to_list_of_clusters(z)\n",
    "    N = A.shape[0]\n",
    "    ratio_cut = 0\n",
    "    \n",
    "    for cluster in nodes_clusters:\n",
    "      nodes_set = set(cluster) # convert to set to make the time complexity for in checks on average O(1)\n",
    "      not_c = [i for i in range(N) if i not in nodes_set] # V\\c_idx\n",
    "      cut = A[cluster][:, not_c].sum() # sum of inter-cluster edge weights\n",
    "      ratio_cut += cut / len(cluster)\n",
    "    ##########################################################\n",
    "    return ratio_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qb9vOiLFGDGu"
   },
   "source": [
    "## 2.2. Compute normalized cut (5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1RzbkhAGDGv"
   },
   "source": [
    "**Important**: if a cluster only contains a single node, define its volume to be 1 to avoid division by zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWlYs5ZsGDGw"
   },
   "outputs": [],
   "source": [
    "def compute_normalized_cut(A: sp.csr_matrix, z: np.array) -> float:\n",
    "    \"\"\"Compute the normalized cut for the given partition of the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster indicators for each node.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    norm_cut : float\n",
    "        Value of the normalized cut for the given partition of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    nodes_clusters = labels_to_list_of_clusters(z)\n",
    "    N = A.shape[0]\n",
    "    norm_cut = 0\n",
    "\n",
    "    for cluster in nodes_clusters:\n",
    "      nodes_set = set(cluster) # convert to set to make the time complexity for in checks on average O(1)\n",
    "      not_c = [i for i in range(N) if i not in nodes_set] # V\\c_idx\n",
    "      cut = A[cluster][:, not_c].sum() # sum of inter-cluster edge weights\n",
    "      vol = A[cluster].sum() # sum degree of nodes in cluster\n",
    "      norm_cut += cut/vol\n",
    "    ##########################################################\n",
    "    return norm_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdUsQm4WGDGz"
   },
   "source": [
    "Notice, how using the unnormalized Laplacian leads to a much better ratio cut, while the normalized Laplacian leads to better normalized cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_HGBVokGDG1"
   },
   "outputs": [],
   "source": [
    "num_clusters = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "kdIq2h6iGDG5",
    "outputId": "116e7f03-ea61-42ea-840c-a76b7141d5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using L_unnorm:\n",
      " ratio cut = 369.109\n",
      " normalized cut = 5.000\n",
      " sizes of partitions are: [3379, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12903)\n",
    "norm_laplacian = False\n",
    "z_unnorm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_unnorm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_unnorm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_unnorm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_unnorm)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "YcMhzfrOGDG9",
    "outputId": "f56578e5-715c-44d0-c62a-9b7f2cf845e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using L_norm:\n",
      " ratio cut = 5942.851\n",
      " normalized cut = 4.343\n",
      " sizes of partitions are: [350, 742, 389, 754, 572, 577]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12323)\n",
    "norm_laplacian = True\n",
    "z_norm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_norm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_norm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_norm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_norm)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtmHOtmHGDHA"
   },
   "source": [
    "# 3. Visualize the results (5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_0Pkj7GGDHB"
   },
   "source": [
    "In the final part of the assignment, your task is to print out the 5 most popular types of restaurants visited by the users in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iav9hDn_GDHB"
   },
   "outputs": [],
   "source": [
    "def print_top_categories_for_each_cluster(top_k: int, z: np.array, F: sp.csr_matrix, categories: List[str]):\n",
    "    \"\"\"Print the top-K categories among users in each cluster.\n",
    "    For each cluster, the function prints names of the top-K categories,\n",
    "    and number of users that like the respective category (separated by a comma).\n",
    "    The function doesn't return anything, just prints the output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    top_k : int\n",
    "        Number of most popular categories to print for each cluster.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster labels.\n",
    "    F : sp.csr_matrix, shape [N, C]\n",
    "        Matrix that tells preferences of each user to each category.\n",
    "        F[i, c] = 1 if user i gave at least one positive review to at least one restaurant in category c.\n",
    "    categories : list, shape [C]\n",
    "        Names of the categories.\n",
    "        \n",
    "    \"\"\"\n",
    "    ##########################################################\n",
    "    # YOUR CODE HERE\n",
    "    nodes_clusters = labels_to_list_of_clusters(z)\n",
    "    for c_idx, cluster in enumerate(nodes_clusters):\n",
    "      preferences = sum(F[cluster])\n",
    "      top_k_pref = np.argsort(-preferences)[:top_k]\n",
    "      print('Most popular categories in cluster ', c_idx)\n",
    "      for cat_idx in top_k_pref:\n",
    "          print(' -', categories[cat_idx], ',', int(preferences[cat_idx]))\n",
    "    ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "Vrnz8zLEGDHG",
    "outputId": "e6413e07-df92-40fe-ae9f-aa877ddd9031",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular categories in cluster  0\n",
      " - Seafood , 315\n",
      " - Mexican , 314\n",
      " - Sandwiches , 294\n",
      " - Japanese , 291\n",
      " - Breakfast & Brunch , 286\n",
      "Most popular categories in cluster  1\n",
      " - Breakfast & Brunch , 636\n",
      " - Sandwiches , 528\n",
      " - Italian , 514\n",
      " - Pizza , 482\n",
      " - Coffee & Tea , 473\n",
      "Most popular categories in cluster  2\n",
      " - Specialty Food , 356\n",
      " - Thai , 355\n",
      " - Breakfast & Brunch , 348\n",
      " - Japanese , 333\n",
      " - Ethnic Food , 330\n",
      "Most popular categories in cluster  3\n",
      " - Breakfast & Brunch , 664\n",
      " - Italian , 626\n",
      " - American (Traditional) , 518\n",
      " - Sandwiches , 518\n",
      " - Pizza , 485\n",
      "Most popular categories in cluster  4\n",
      " - Japanese , 507\n",
      " - Breakfast & Brunch , 462\n",
      " - Sandwiches , 435\n",
      " - Italian , 417\n",
      " - Asian Fusion , 414\n",
      "Most popular categories in cluster  5\n",
      " - Japanese , 529\n",
      " - Chinese , 441\n",
      " - Asian Fusion , 414\n",
      " - Sushi Bars , 408\n",
      " - Korean , 406\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(23142)\n",
    "z_norm = spectral_clustering(A, num_clusters, True)\n",
    "r = print_top_categories_for_each_cluster(5, z_norm, F, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.33333333e-01 -4.37607264e-01  2.93891533e-01]\n",
      " [-3.33333333e-01 -3.37028446e-01  8.89831963e-02]\n",
      " [-3.33333333e-01 -4.37607264e-01  2.93891533e-01]\n",
      " [-3.33333333e-01  2.04697370e-15 -5.87783066e-01]\n",
      " [-3.33333333e-01 -5.84088369e-02 -3.82874729e-01]\n",
      " [-3.33333333e-01  5.84088369e-02 -3.82874729e-01]\n",
      " [-3.33333333e-01  4.37607264e-01  2.93891533e-01]\n",
      " [-3.33333333e-01  4.37607264e-01  2.93891533e-01]\n",
      " [-3.33333333e-01  3.37028446e-01  8.89831963e-02]]\n",
      "[[-0.33333333 -0.50825814 -0.13718758]\n",
      " [-0.33333333 -0.35067024  0.03210615]\n",
      " [-0.33333333 -0.50825814 -0.13718758]\n",
      " [-0.33333333  0.17520065  0.61051276]\n",
      " [-0.33333333  0.07323258  0.33107362]\n",
      " [-0.33333333  0.2228469   0.13656023]\n",
      " [-0.33333333  0.3330575  -0.47332518]\n",
      " [-0.33333333  0.3330575  -0.47332518]\n",
      " [-0.33333333  0.2297914   0.11077276]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "def plot_cluster(ebds, epsilon=0.05):\n",
    "    # Rotate embeddings such that node 4 is always embedded straight down\n",
    "    four = ebds[3]\n",
    "    alpha = np.arccos(-four[1] / np.linalg.norm(four))\n",
    "    c, s = np.cos(alpha), np.sin(alpha)\n",
    "    R = np.array([[c, -s], [s, c]])\n",
    "    ebds = ebds @ R\n",
    "\n",
    "    clusters = KMeans(n_clusters=3).fit_predict(ebds)\n",
    "\n",
    "    fig, ax = pp.subplots(1, 1, figsize=(6, 6))\n",
    "    xptp, yptp = ebds.ptp(axis=0) * 0.1\n",
    "    ax.set_xlim((ebds[:, 0].min() - xptp, ebds[:, 0].max() + xptp))\n",
    "    ax.set_ylim((ebds[:, 1].min() - yptp, ebds[:, 1].max() + yptp))\n",
    "\n",
    "    # Disturb points to show nodes that get mapped to the same coordinates\n",
    "    points = ebds + np.random.rand(*ebds.shape) * epsilon\n",
    "\n",
    "    colors = [\"firebrick\", \"seagreen\", \"dodgerblue\"]\n",
    "    bbox_props = dict(boxstyle=\"circle\", alpha=0.5, ec=\"b\", lw=2)\n",
    "    for i, xyc in enumerate(zip(points, clusters)):\n",
    "        xy, c = xyc\n",
    "        bbox_props[\"fc\"] = colors[c]\n",
    "        pp.text(xy[0], xy[1], str(i + 1), bbox=bbox_props,\n",
    "                horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def laplacian(A):\n",
    "    D = A.sum(axis=0)\n",
    "    return np.identity(A.shape[0]) * D - A\n",
    "\n",
    "edges = np.array([\n",
    "    (1, 2, 1), (1, 3, 1), (2, 3, 1), (2, 5, 1), (4, 5, 1),\n",
    "    (4, 6, 1), (5, 6, 2), (6, 9, 1), (7, 8, 3), (7, 9, 1), (8, 9, 1)]).T\n",
    "edges[:2] -= 1\n",
    "A = coo_matrix((edges[2], (edges[0], edges[1])), shape=(9, 9)).toarray()\n",
    "A = A + A.T\n",
    "\n",
    "_, eig = eigh(laplacian(A), eigvals=(0, 2))\n",
    "print(eig)\n",
    "# fig, _ = plot_cluster(eig)\n",
    "# fig.savefig(\"problem_3_pre.png\")\n",
    "# 0.31622777\n",
    "#\n",
    "A[5, 8] = 40\n",
    "A[8, 5] = 40\n",
    "_, eig = eigh(laplacian(A), eigvals=(0, 2))\n",
    "print(eig)\n",
    "# fig, _ = plot_cluster(eig)\n",
    "# fig.savefig(\"problem_3_post.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "spectral_clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
